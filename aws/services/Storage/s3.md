# s3

- scalable, distributed object storage accessible from anywhere

## my thoughts

## links

- [bucket policy examples](https://docs.aws.amazon.com/en_us/AmazonS3/latest/userguide/example-bucket-policies.html)
- [buckets](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingBucket.html)
- [event notifications](https://docs.aws.amazon.com/AmazonS3/latest/userguide/EventNotifications.html)
- [https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html](https://aws.amazon.com/s3/storage-classes/)
- [inventory](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-inventory.html)
- [landing page](https://aws.amazon.com/s3/?did=ap_card&trk=ap_card)
- [naming rules](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html)
- [replication](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html)
- [server side encryption](https://docs.aws.amazon.com/AmazonS3/latest/userguide/serv-side-encryption.html)
- [storage class analysis](https://docs.aws.amazon.com/AmazonS3/latest/userguide/analytics-storage-class.html)
- [versioning](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html)
- [storage lens](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens.html)
- [access points](https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-access-points.html)

## best practices

- determine your folder hierarchy upfront: i.e your object prefixes
- s3 bucket policies vs iam policies
  - IAM policies: whenever you have alot of private buckets or prefer to centralize all of your policies
  - s3 bucket policies: simple cross-account access or complex policies that breach the IAM policy size limit
- object versioning
  - make sure to delete unused versions of an object to reduce costs
- automate object storage with lifecycle configurations
  - e.g. from standard > standard-IA > glacier: move to a lower cost longer term storage every 30 days
  - object types: periodic logs or any data that becomes less frequently accessed overtime
- static website hosting is a mismoner: you can still use client-side JS to load content dynamically
  - the idea is that there isnt a webserver responding to requests

### anti patterns

## features

- scalable storage with 11 9s of data durability
- multiple storage classes to fit R/W requirements
- various mechanisms for authnz; Configuring and enforcing data access controls
- REST APIs designed to work with any internet-development toolkit.
  - supports at least 3,500 requests per second to add data and 5,500 requests per second to retrieve data
- filter data retrieved by lambda with S3 Select (SQL)
- automatically Moving and storing data across different S3 storage classes
- parallel requests per object prefix
- use cases
  - big data analytics analytics
  - application data/log files/media hosting
  - backup and archival
  - software delivery: up to 5tb per object
  - static content/websites: html, css and clientside js
  - data lakes, cheap data store

### pricing

- Storage pricing
- Request and data retrieval pricing
- Data transfer and transfer acceleration pricing
- Data management and analytics pricing
- Price to process your data with S3 Object Lambda
- Amazon S3 pricing varies based on the AWS Region where it resides.
- costs are incurred for all objects in a bucket, including all object versions

## basics

- s3 is a flat, non-hierarchical structure where bucket names must be unique across all aws accounts and regions and bucket objects fake hierarchy via their name prefixes
- its all about buckets, and objects
- folders are just the prefixes you give to objects in buckets

### buckets

- All objects are stored in S3 buckets and can be organized with shared names called prefixes.
- bucket name: must be DNS compliant and unique across all of AWS, even tho the bucket itself is region specific
  - the bucket name becomes part of the URL for objects stored within

### objects

- files stored in buckets
  - 5tb limit per object
- object key: the name of the object
- object url schema: `https://BUCKET_NAME.s3.REGION.amazonaws.com/PREFIX/OBJECT_KEY`
- parallel requests: scale per prefix
  - Write: 3.5k writes per second
  - Read: 5.5k reads per second
- strong read-after-write consistency for PUT and DELETE actions
- strongly consistent read operations on Amazon S3 Select, Amazon S3 access control lists, Amazon S3 object tags, and object metadata

### versioning

- uploading an item with the same URI creates an object with a new version ID
  - enables preserve, retrieve, and restore operations
- object deletion:
  - deleting an object does not permanently remove it, instead a delete marker is placed on the object
  - to restore an object, you simply remove the marker
  - MFA delete: bucket feature that requires MFA for delete operations
- version states
  - unversioned: object versioning is disabled
  - versioning-enabled: once enabled, it can never return to an unversioned state
  - versioning-suspended: all new objects will not have a version, but existing objects will keep their versions

#### object locks

- configured at the object level and bucket levels
- enforce write-once-read-many (WORM) policies
- blocks object version deletion during a retention period
  - Retain Until Date
  - Legal Hold Date
- modes
  - Governance mode: AWS accounts with specific IAM permissions are able to remove S3 Object Lock from objects.
  - Compliance mode: no user or root account can remove the protection.

### replication

- replicate objects and their respective metadata and object tags to one or more destination buckets into the same or different AWS Regions
- Cross-Region Replication: CRR; replicate from a source S3 bucket to one or more destination buckets in different AWS Region.
- Same-Region Replication: SRR; replicates objects between buckets in the same AWS Region
- Replication Time Control: S3 RTC; meet compliance requirements for data replication by providing an SLA and visibility into replication times.

### batch operations

- streamlines data management at any scale, whether you store thousands of objects or a billion.
- when batch request completes you receive a notification and a completion report of all changes made.

### Inventory

- daily/weekly report listing buckets/objects and their corresponding metadata
- formats
  - CSV report
  - Apache optimized row columnar (ORC)
  - Apache Parquet output files

### Event Notifications

- trigger workflows, alerts, and invoke AWS Lambda when a specific change is made to your S3 resources.

### Object Lambda

- uses AWS Lambda functions to process the output of GET, HEAD, and LIST request automatically

### security

- IAM: create users and manage their respective access permissions
- ACLS: to make individual objects accessible to authorized users
- Bucket policies: configure permissions for all objects within a single S3 bucket
- Query String Authentication: to grant time-limited access to others with temporary URLs

#### authnz

- all s3 resources are private by default: only the user/aws account can view resources
- bucket permissions: determines bucket + overall object permissions
  - object ownership: acls are disabled by default
- object permissions: for specific objects
- public access: 3 step process
  - unblock public access on bucket
  - enable ACLs for object ownership, confusing this is done at the bucket level as well
  - go to a specific object and make it public

#### Access Points

- managing data access to shared datasets by creating access points with names and permissions specific to each application or sets of applications.

#### Block Public Access

- ensures S3 buckets and objects do not have public access.
- override other S3 access permissions: regardless of how an object is added, how a bucket is created, or whether there are existing access permissions.
- uses AWS Trusted Advisor bucket permission checks, AWS CloudTrail logs, and Amazon CloudWatch alarms

#### s3 bucket policies

- resource policies

##### Access Analyzer

- monitors and evaluates bucket access policies
- download Access Analyzer for S3 findings as a CSV report.

#### encryption

- at rest: three mutually exclusive options, depending on how you choose to manage the encryption keys.
  - Amazon S3-managed Keys (SSE-S3): the base level of encryption for every bucket and all new objects
  - AWS KMS keys stored in AWS KMS (SSE-KMS)
  - Customer-provided keys (SSE-C)

### storage classes

- supports a specific data access level at corresponding costs or geographic location
- all about storage duration and access patterns
  - latency of access: when you need something, do you need it immediately?
  - frequency of access: do you need stuff often
  - storage duration: long term vs short term
- if you dont specify a storage class while uploading an object s3 uses the default (standard) class
- redundancy
  - one zone: the only storage class that doesnt store data redundantly across availability zones
  - all other classes store data across a minimum of 3 availability zones

#### standard (frequent access)

- general purpose for cloud apps, dynamic websites, content distribution, mobile/gaming apps, big data analytics

#### standard-infrequent access (standard IA)

- less frequent, highly available
- data that is access less frequently, but requires rapid access when needed
  - long term backups, disaster recovery files, etc
  - same durability, throughput and latency of s3 standard

#### one zone-infrequent access (one zone-IA)

- less frequent, less available
- stores data in a single availability zone
  - secondary backups or easily recreatable data

#### intelligent-tiering

- for data with unknown/changing access patterns
- s3 monitors object access patterns and moves them between 3 tiers
  - frequent access
  - infrequent access
  - archive instance

#### glacier storage classes (instant, flexible, archive)

- see [markdown file](./s3-glacier.md)
- for archiving data that is rarely access and requires millisecond retrieval
  - cost savings up 68% off standard-IA storage class
  - same latency and throughput performance of standard-IA

#### s3 on outposts

- see [markdown file](./s3-outposts.md)
- object storage for on-premise Outposts environment
- for workloads with local data residency requirements or onpremise performance reasons

### lifecycle policies

- automate objects/groups of objects to appropriate storage tiers
- transition actions: define when objects should transition to another storage class
- expiration actions: define when objects expire and should be permanently deleted

### Analytics

#### Storage Class Analysis

- analyzes storage access patterns for determining when to transition less frequently accessed storage to a lower-cost storage class.
- use the report to configure an S3 Lifecycle policy that makes the data transfer.
  - all bucket objects
  - filters: by prefix, by object tags, or by both prefix and tags.

#### Storage Lens

- organization-wide visibility into object storage usage and activity trends.
  - drill-down options to generate insights at the organization, account, Region, bucket, or even prefix level.
- automated recommendations to help you optimize your storage.

#### s3 Select (SQL queries)

- run big data analytics directly on your data stored in Amazon S3.
- retrieves a subset of an objectâ€™s data instead of the entire object
- build a data lake

## considerations

- region
- bucket name: 3-63 chars, DNS compatible
- object ownership: either public or define an ACL
- IAM policies vs s3 bucket policies
  - iam attached to users/groups/roles
  - bucket policies.....attached to buckets ;)
- bucket versioning
- storage lifecycle

## integrations

- s3 one of the most widely integrated services

### cloudwatch

### cloudtrail

### lambda

### VPC

- VPC endpoints: connect your on-premises applications directly with S3 over AWS Direct Connect or AWS VPN.
  - set security groups and configure VPC endpoint policies for your interface VPC endpoints for additional access controls.

### PrivateLink

- private connectivity between Amazon S3 and on premises environment.
- provision private endpoints in a VPC to allow direct access to S3 from on-premises using private IPs from your VPC.

### DirectConnect

### VPN

### KMS

- enable S3 Bucket Keys to decrease request traffic from Amazon S3 to AWS KMS. By doing this, you can reduce the cost of encryption.

### Trusted Advisor

### Macie

- creates and evalutes S3 inventory automatically
- alert on any of the following:
  - Any publicly accessible buckets
  - Unencrypted buckets
  - Buckets shared or replicated with AWS accounts outside of your organization

### Athena

- queries your data in Amazon S3 without needing to extract and load it into a separate service or platform
- commonly used for unplanned data discovery.

### Redshift Spectrum

- runs SQL queries directly against data at rest in Amazon S3
- more appropriate for complex queries and large datasets (up to exabytes)

### EFS

### EBS

### Storage Gateway

- connect and extend your on-premises applications to AWS Storage, all while caching data locally for low-latency access.

### Lake Formation

- create a data lake and centrally define and enforce security, governance, and auditing policies.
- collects data across your databases and S3 resources
  - moves the data into a new data lake in Amazon S3
  - cleans and classifies it using machine learning algorithms.

### DataSync

- automate data transfers between on-premises storage and S3
- transfer data at speeds up to 10 times faster than open-source tools.

### Transfer Family

- fully managed that enables secure file exchanges with third parties using SFTP, FTPS, and FTP.
