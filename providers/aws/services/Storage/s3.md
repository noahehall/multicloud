# s3

- scalable, distributed object storage accessible from anywhere on the web

## my thoughts

## links

- [bucket policy examples](https://docs.aws.amazon.com/en_us/AmazonS3/latest/userguide/example-bucket-policies.html)
- [buckets](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingBucket.html)
- [event notifications](https://docs.aws.amazon.com/AmazonS3/latest/userguide/EventNotifications.html)
- [https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html](https://aws.amazon.com/s3/storage-classes/)
- [inventory](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-inventory.html)
- [landing page](https://aws.amazon.com/s3/?did=ap_card&trk=ap_card)
- [naming rules](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html)
- [replication](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html)
- [server side encryption](https://docs.aws.amazon.com/AmazonS3/latest/userguide/serv-side-encryption.html)
- [storage class analysis](https://docs.aws.amazon.com/AmazonS3/latest/userguide/analytics-storage-class.html)
- [versioning](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html)
- [storage lens](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens.html)
- [access points](https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-access-points.html)
- [prefixes](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-prefixes.html)
- [object tagging](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-tagging.html)
- [virtual hosting](https://docs.aws.amazon.com/AmazonS3/latest/userguide/VirtualHosting.html)
- [regions and endpoints](https://docs.aws.amazon.com/general/latest/gr/s3.html)
- [request routing](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingRouting.html)
- [multipart uploads](https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html)
- [block public access](https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html)
- [presigned url examples](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/s3-example-presigned-urls.html)
- [object ownership](https://docs.aws.amazon.com/AmazonS3/latest/userguide/about-object-ownership.html) -[security](https://aws.amazon.com/s3/security/)
- [using server side encryption](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingServerSideEncryption.html)
- [using KMS encryption](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html)
- [using encryption with customer keys](https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html)
- [usig client side encryption](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html)

## best practices

- determine your folder hierarchy upfront
- s3 bucket policies vs iam policies
  - IAM policies: whenever you have alot of private buckets or prefer to centralize all of your policies
  - s3 bucket policies: simple cross-account access or complex policies that can exceed the IAM policy size limit
- object versioning
  - make sure to delete unused versions of an object to reduce costs
- automate object storage with lifecycle configurations
  - e.g. from standard > standard-IA > glacier: move to a lower cost longer term storage every X days
  - object types: periodic logs or any data that becomes less frequently accessed overtime
- static website hosting is a mismoner: you can still use client-side JS to load content dynamically
  - the idea is that there isnt a webserver responding to requests
  - Use a dot (.) in the name only if the bucket's intended purpose is to host an S3 static website
  - if you include dots in a bucket name that is not a static website
    - can't use virtual-host-style addressing over HTTPS, unless you perform your own certificate validation.
  - if you use dots
    - SSL wildcard certificate matches only buckets that do not contain dots
- Path style URLs are going to be deprecated; dont waste your time using them
- multipart uploads
  - recommened for objects over 100mb
  - enable the ability to clean incomplete multipart uploads in the lifecycle settings even if not explicitly using multipart uploads
  - configure a lifecycle rule using the AbortIncompleteMultipartUpload action to minimize your storage costs.
  - Some applications default to multipart uploads when uploading files over a particular application-dependent size and failed or incomplete uploads will result in increased storage costs.
- prevent accidental public access by reading the section somewhere in this doc ;)~

### anti patterns

## features

- scalable storage with 11 9s of data durability
- multiple storage classes to fit R/W requirements
- various mechanisms for authnz; Configuring and enforcing data access controls
- REST APIs designed to work with any internet-development toolkit.
  - supports at least 3,500 write per sec and 5,500 reads per sec
- filter data retrieved by lambda with S3 Select (SQL)
- automatically Moving and storing data across different S3 storage classes
- parallel requests per object prefix
- use cases
  - big data analytics analytics
  - application data/log files/media hosting
  - backup and archival
  - software delivery
  - static content/websites: html, css and clientside js
  - data lakes, cheap data store

### pricing

- Storage
- Request and data retrieval
- Data transfer and transfer acceleration pricing
- Data management and analytics
- process your data with S3 Object Lambda
- varies based on the AWS Region where it resides.
- incurred for all objects & object versions in a bucket

## basics

- s3 is a flat, non-hierarchical structure where bucket names must be unique across all aws accounts and regions and bucket objects fake hierarchy via their name prefixes

### buckets

- All objects are stored in S3 buckets and can be organized with shared names called prefixes.
- bucket name: must be DNS compliant and unique across all of AWS, even tho the bucket itself is region specific
  - consist only of lowercase letters, numbers, dots (.), and hyphens (-).
  - the bucket name becomes part of the URL for objects stored within
- must be emptied before deleted; another account can use the bucket name after 24 hours
- buckets cannot be nested

#### Regions

- globally viewable service: you dont specify a region within the console
- buckets are region specific: determines the location where the objects physically reside
  - should be local to your users or consumers to optimize latency, minimize costs, or to address regulatory requirements.

#### replication

- replicate objects and their respective metadata and object tags to one or more destination buckets into the same or different AWS Regions
- Cross-Region Replication: CRR; automatically replicate data to multiple regions
  - entire bucket
  - use tags to replicate matching objects
- Same-Region Replication: SRR; automatic and asynchronous replication of newly uploaded S3 objects to another bucket in the same region and redundancy as the destination storage class
  - aggregate logs from different S3 buckets for in-region processing
  - configure live replication between test and development environments
  - address data sovereignty and compliance requirements by keeping a copy of your objects in the same AWS Region as the original.
- Replication Time Control: S3 RTC; meet compliance requirements for data replication by providing an SLA and visibility into replication times.

#### consistency

- strong read-after-write: for all GET, PUT, LIST, HEAD requests, Access Control Lists, object tags, and other metadata
  - without changes to performance or availability
  - without sacrificing regional isolation for applications
  - at no additional cost
- eventual: bucket operations like reading a bucket policy or metadata,

#### Static Websites

- configure a bucket for website hosting and then upload your content
  - must enable website hosting
  - set public read permissions
  - create and add an index document.
  - configure redirects, web traffic logging, and a custom error document.
- create, update, and delete the website configuration programmatically by using the AWS SDKs.

### objects

- files stored in buckets: 5tb (api) or 160gb (console) per object limit
  - key: the fullpath to object in a bucket: prefix + filename
  - metadata: statoc key value pairs set at creation time; cannot be modified post-upload
  - access control: supports both resource-based and user-based access controls.
  - version id: automatically generated identifier
  - value: the size & actual content that you are storing; can be any sequence of bytes, meaning it can be the whole object or a range of bytes within an object that an application needs to retrieve
- object url schema: `https://BUCKET_NAME.s3.REGION.amazonaws.com/PRE/FIX/OBJECT_KEY`
- parallel requests: scale per prefix
  - Write: 3.5k writes per second
  - Read: 5.5k reads per second

#### versioning

- uploading an item with the same URI creates an object with a new version ID
  - enables preserve, retrieve, and restore operations
- object deletion:
  - deleting an object does not permanently remove it, instead a delete marker is placed on the object
  - to restore an object, you simply remove the marker
  - MFA delete: bucket feature that requires MFA for delete operations
- version states
  - unversioned: object versioning is disabled
  - versioning-enabled: once enabled, it can never return to an unversioned state
  - versioning-suspended: all new objects will not have a version, but existing objects will keep their versions

#### lifecycle policies

- automate objects/groups of objects to appropriate storage tiers
- transition actions: define when objects should transition to another storage class
- expiration actions: define when objects expire and should be permanently deleted
  - clean up incomplete multipart uploads
- Lifecycle configuration: XML file that consists of a set of rules with predefined actions that you want Amazon S3 to perform on objects during their lifetime

### object locks

- configured at the object and bucket levels
- enforce write-once-read-many (WORM) policies
- blocks object version deletion during a retention period
  - Retain Until Date
  - Legal Hold Date
- modes
  - Governance mode: AWS accounts with specific IAM permissions are able to remove S3 Object Lock from objects.
  - Compliance mode: no user or root account can remove the protection.

### batch operations

- streamlines data management at any scale
- when batch request completes you receive a notification and a completion report of all changes made.

### Inventory

- daily/weekly report listing buckets/objects and their corresponding metadata
- formats
  - CSV report
  - Apache optimized row columnar (ORC)
  - Apache Parquet output files

### Event Notifications

- trigger workflows, alerts, and invoke AWS Lambda when a specific change is made to your S3 resources.

### Object Lambda

- uses AWS Lambda functions to process the output of GET, HEAD, and LIST requests

### security

- IAM: create users and manage their respective access permissions
- ACLS: to make individual objects accessible to authorized users
- Bucket policies: configure permissions for all objects within a single S3 bucket
- Query String Authentication: to grant time-limited access to others with temporary URLs

#### authnz

- all s3 resources are private by default: only the user/aws account can view resources
- bucket permissions: determines bucket + overall object permissions
  - object ownership: acls are disabled by default
- object permissions: for specific objects
- Pre-Signed URLS: grant temporary time access to others
- Access Control Lists: predate IAM/Bucket Policies; dont use s3 ACLs

#### Access Points

- managing data access to shared datasets by creating access points with names and permissions specific to each application or sets of applications.

#### public access

- is blocked by default at the account and bucket level
  - if enabled at the account level, it overrides the bucket level
- 3 step process
  - unblock public access on bucket
  - enable ACLs for object ownership, confusing this is done at the bucket level as well
  - go to a specific object and make it public
- block public access settings
  - block all public access: overrides all configured ACLs and bucket policies that would normally grant public access
    - this enables all other options below
  - block public access granted through
    - new ACLs: only affects the creation of new public ACLs; they cannot grant public access
    - ANY ACLS; affects all ACLs; public access cannot be granted via an ACL
    - new bucket policies: only afters new bucket policies; they cannot grant public access
    - ANY bucket policies;: affects all bucket policies
- preventing accidental public acess
  - use s3 block public access setting at the account level
  - audit existing ACLs and policies
  - dont allow public access at the bucket level unless explicitly needing it

#### Private Access

- ensures S3 buckets and objects do not have public access.
- override other S3 access permissions: regardless of how an object is added, how a bucket is created, or whether there are existing access permissions.
- uses AWS Trusted Advisor bucket permission checks, AWS CloudTrail logs, and Amazon CloudWatch alarms

#### s3 bucket policies

- resource-based policies that replace legacy s3 ACLs
  - must include a PRINCIPAL statemewnt
  - size limit of up 20 kb
- use cases
  - grant cross-account permissions to other AWS accounts or users in another account, without using IAM roles.
    - IAM user policies are for users in your account, not other accounts
  - IAM policies reach the size limits for users, groups, roles.
  - prefer to keep access control policies in the Amazon S3 environment.

#### IAM Policies

- IAM policies have a size limit of
  - 2 kb for users,
  - 5 kb for groups,
  - 10 kb for roles
- no PRINCIPAL stanza as the principal is whichever user the policy is applied to.
- use cases
  - easier centralized management all of your permissions. beyond S3
  - easier to manage than having to define a large number of Amazon S3 bucket policies.
  - prefer to keep access control policies in the IAM environment.

#### Query String AuthN

- aka presigned urls: use query parameters to provide request information, including the authentication information
  - Anyone who receives the presigned URL can then access the object
- requirements:
  - provide your security credentials
    - IAM instance profile: value for 6 hrs
    - STS token: valid for 36 hours
    - iam user: valid for 7 days
  - specify a bucket name, an object key, an HTTP method (PUT for uploading objects),
  - an expiration date and time.
  - someone who has permission to perform the operation must create the presigned URL.
- use cases
  - grant temporary access to objects
  - programmatically generate a presigned URL to allow uploads

#### IAM Access Analyzer

- review all buckets that grant public/shared access
  - bucket access control lists (ACLs)
  - bucket policies,
  - access point policies
- monitors and evaluates policies & For each public or shared bucket, you receive findings that report the source and level of public or shared access.
  - can download as a CSV report.

#### Objet ownership

- 2 modes
  - object writer: the account that creates the object owns the object
  - bucket owner preferred: buckect owner owns the object if object uploaded with `bucket-owner-full-control` ACL
    - else object owned by uploader
    - this can be enforced through a bucket policy requiring all objects to be uploaded with the ACL

#### encryption

- at rest: three mutually exclusive server side encryptin options, depending on how you choose to manage the encryption keys.
  - S3-managed Keys: SSE-S3; the base level of encryption for every bucket and all new objects
    - each object encrypts with a unique key
    - encrypts the key itself with a master key that it regularly rotates
  - KMS keys: SSE-KMS; Server-Side Encryption with Customer Master Keys (CMKs) Stored in KMS
    - additional benefits and charges for using this service compared with SSE-S3
    - separate permissions for the use of a CMK that provides added protection against unauthorized access of your objects in Amazon S3
    - an audit trail showing when and who used the CMK
    - create and manage customer managed CMKs, or use AWS managed CMKs that are unique to you, your service, and your Region.
  - Customer-provided keys: SSE-C;
    - you manage the encryption keys
    - S3 manages the encryption before writing to disk, and decryption on object access

### storage classes

- supports a specific data access level at corresponding costs or geographic location
- all about storage duration and access patterns
  - latency of access: when you need something, do you need it immediately?
  - frequency of access: do you need stuff often
  - storage duration: long term vs short term
- if you dont specify a storage class while uploading an object s3 uses the default (standard) class
- redundancy
  - one zone: the only storage class that doesnt store data redundantly across availability zones
  - all other classes store data across a minimum of 3 availability zones

#### standard (frequent access)

- general purpose for cloud apps, dynamic websites, content distribution, mobile/gaming apps, big data analytics

#### standard-infrequent access (standard IA)

- less frequent, highly available
- data that is access less frequently, but requires rapid access when needed
  - long term backups, disaster recovery files, etc
  - same durability, throughput and latency of s3 standard

#### one zone-infrequent access (one zone-IA)

- less frequent, less available
- stores data in a single availability zone
  - secondary backups or easily recreatable data

#### intelligent-tiering

- for data with unknown/changing access patterns
- s3 monitors object access patterns and moves them between 3 tiers
  - frequent access
  - infrequent access
  - archive instance

#### glacier storage classes (instant, flexible, archive)

- see [markdown file](./s3-glacier.md)
- for archiving data that is rarely access and requires millisecond retrieval
  - cost savings up 68% off standard-IA storage class
  - same latency and throughput performance of standard-IA

#### s3 on outposts

- see [markdown file](./s3-outposts.md)
- object storage for on-premise Outposts environment
- for workloads with local data residency requirements or onpremise performance reasons

### Analytics

#### Storage Class Analysis

- analyzes storage access patterns for determining when to transition less frequently accessed storage to a lower-cost storage class.
- use the report to configure an S3 Lifecycle policy that makes the data transfer.
  - all bucket objects
  - filters: by prefix, by object tags, or by both prefix and tags.

#### Storage Lens

- organization-wide visibility into object storage usage and activity trends.
  - drill-down options to generate insights at the organization, account, Region, bucket, or even prefix level.
- automated recommendations to help you optimize your storage.

#### s3 Select (SQL queries)

- run big data analytics directly on your data stored in S3.
- retrieves a subset of an object’s data instead of the entire object
- build a data lake

### Tags

- [also see markdown file](../globalArchitecture.md)

#### Bucket tags

- label buckets with AWS-generated tag or user-defined tag
  - generated: AWS defines, creates, and applies the AWS-generated tag, createdBy,
  - user defined: whatever you want

#### object tags

- a way to categorize and query your storage
- up to 10 tags per object
- keys can be up to 128 characters in length
- values can be up to 255 characters in length
- Key and tag values are case sensitive

#### tag sets

- all of the tags that are assigned to a bucket or object, up to 50
  - keys must be unique
- to modify tag sets via api: download all > modify > upload all

### REST API

#### path style URLs

- there is a deprecation plan in the works for path-style URLs on newly created bucket
- bucket name comes after the global or region-specific endpoint.
  - `https:/region-specific-endpoint/bucket/object`
  - The bucket is always a subdomain of s3.amazonaws.com
  - when DNS resolves this URL the endpoint will always be a subdomain of s3.amazonaws.com.
- multiple accounts for different companies and owners map to this single subdomain, `s3.amazonaws.com`

#### Virtual hosted-style URLs

- If you need a customized URL
  - naming your bucket after your registered domain name
  - making that name a DNS alias for Amazon S3.
  - e.g. http://my.bucket-name.com
- the bucket name becomes the subdomain in the URL
  - `https://BUCKET.REGION_ENDPOINT/PREFIX/OBJECT`
- can also publish to the "root directory" of your bucket's virtual server.
  - many existing applications search for files in this standard location. For example, favicon.ico, robots.txt, and crossdomain.xml are all expected to be found at the root.
- using virtual-hosted–style buckets with SSL
  - SSL wildcard certificate matches only buckets that do not contain dots

#### DNS Requests

- step by step
  - client makes a DNS request to get the address of s3.amazonaws.com.
  - receives one or more IP addresses for facilities that can process the request
- temporary redirects: Due to the distributed nature of Amazon S3, requests could temporarily route to the wrong Region
  - s3 will respond with a temporary redirect with the correct endpoint
  - most likely to occur immediately after the creation or deletion of buckets.

#### CRUD

- concurrency: last request received is stored.
  - s3 orders all of the requests that it receives
  - possible that if you send two requests nearly simultaneously, the received requests will be in a different order than sent.
- PUT: add an object to a bucket
  - must have WRITE permissions on a bucket in order to add an object
  - new object overwrites the existing object
- GET: resumable operatoin to retrieve a whole object or parts of an object
  - Range HTTP header: specifying the bytes you want
- DELETE: either a single object or multiple objects in a single delete request
  - side effect depends if object versioning is enabled
    - disabled: permanently delete; unrecoverable
    - enabled:
      - specify version id: permanently delete; unrecoverable
      - without version id: soft delete; recoverable
        - S3 inserts a delete marker that becomes the current version of the object.
        - retrieving an object that has a delete marker returns a 404

#### Multipart Upload API

- upload/copy operations
- allows you to upload a single object as a set of parts
- If transmission of any part fails, you can re-transmit just that part without having to re-transmit all the parts
- Improved throughput - You can upload parts in parallel to improve throughput.
- Quick recovery from any network issues - Smaller part size minimizes the impact of restarting a failed upload due to a network error.
- Pause and resume object uploads - You can upload object parts over time. Once you initiate a multipart upload there is no expiry; you must explicitly complete or abort the multipart upload.
- Begin an upload before you know the final object size - You can upload an object as you are creating it.

## considerations

- region
- buckets: 1 to 100 buckets in each AWS account; increasable to 1000
  - name: 3-63 chars, DNS compatible, globally unique, cannot be renamed
  - ownership cannot be transfered to other accounts
- object ownership
- IAM policies vs s3 bucket policies
  - iam attached to users/groups/roles
  - bucket policies.....attached to buckets ;)
- bucket versioning
- storage lifecycle

## integrations

- s3 is one of the most widely integrated services
- pretty sure it integrates with everything

### cloudwatch

### cloudtrail

### lambda

### VPC

- VPC endpoints
  - set security groups and configure VPC endpoint policies for your interface VPC endpoints for additional access controls.

### PrivateLink

- provision private endpoints in a VPC

### DirectConnect

### VPN

### KMS

- enable S3 Bucket Keys to decrease request traffic from Amazon S3 to AWS KMS. By doing this, you can reduce the cost of encryption.

### Trusted Advisor

### Macie

- creates and evalutes S3 inventory automatically
- alert on any of the following:
  - Any publicly accessible buckets
  - Unencrypted buckets
  - Buckets shared or replicated with AWS accounts outside of your organization

### Athena

- queries your data in Amazon S3 without needing to extract and load it into a separate service or platform
- commonly used for unplanned data discovery.

### Redshift Spectrum

- runs SQL queries directly against data at rest in Amazon S3
- more appropriate for complex queries and large datasets (up to exabytes)

### EFS

### EBS

### Storage Gateway

- connect and extend your on-premises applications to AWS Storage, all while caching data locally for low-latency access.

### Lake Formation

- create a data lake and centrally define and enforce security, governance, and auditing policies.
- collects data across your databases and S3 resources
  - moves the data into a new data lake in Amazon S3
  - cleans and classifies it using machine learning algorithms.

### DataSync

- automate data transfers between on-premises storage and S3
- transfer data at speeds up to 10 times faster than open-source tools.

### Transfer Family

- fully managed that enables secure file exchanges with third parties using SFTP, FTPS, and FTP.
