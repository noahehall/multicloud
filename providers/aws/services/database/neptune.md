# neptune

- fully managed serverless graph database for highly connected, multi-layered datasets
- must be deployed in a VPC
- [tinker pop property graph](./neptune-propertyGraph-tinkerPop.md)
- [Neo4j's openCypher property graph](./neptune-propertyGrpah-openCypher.md)
- [w3c sparql RDF graph](./neptune-rdfGraph-w3cSparql.md)
- [neptune local](./neptune-local.md)
- bookmark
  - [logging and monitoring](https://docs.aws.amazon.com/neptune/latest/userguide/security-monitoring.html)
  - [graph notebooks](https://docs.aws.amazon.com/neptune/latest/userguide/graph-notebooks.html)
  - [setup](https://docs.aws.amazon.com/neptune/latest/userguide/neptune-setup.html)
  - [migration](https://docs.aws.amazon.com/neptune/latest/userguide/migrating.html)
  - [loading data](https://docs.aws.amazon.com/neptune/latest/userguide/load-data.html)
  - [querying](https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-queries.html)
  - [visualization](https://docs.aws.amazon.com/neptune/latest/userguide/visualization-tools.html)
  - [serverless](https://docs.aws.amazon.com/neptune/latest/userguide/neptune-serverless.html)
  - [streams](https://docs.aws.amazon.com/neptune/latest/userguide/streams.html)
  - [full text search](https://docs.aws.amazon.com/neptune/latest/userguide/full-text-search.html)
  - [lambda fns](https://docs.aws.amazon.com/neptune/latest/userguide/lambda-functions.html)
  - [monitoring](https://docs.aws.amazon.com/neptune/latest/userguide/monitoring.html)
  - [exporting data](https://docs.aws.amazon.com/neptune/latest/userguide/neptune-data-export.html)
  - [best practices](https://docs.aws.amazon.com/neptune/latest/userguide/best-practices.html)
  - [apis](https://docs.aws.amazon.com/neptune/latest/userguide/using-neptune-apis.html)
  - [control plane ref](https://docs.aws.amazon.com/neptune/latest/userguide/api.html)
  - [data plane ref](https://docs.aws.amazon.com/neptune/latest/userguide/data-api.html)

## my thoughts

## links

- [AAA: best practices](https://docs.aws.amazon.com/neptune/latest/userguide/best-practices.html)
- [AAA: neptunes data model](https://docs.aws.amazon.com/neptune/latest/userguide/feature-overview-data-model.html)
- [AAA: reference architecture](https://github.com/aws-samples/aws-dbs-refarch-graph)
- [AAA: neptune engine releases](https://docs.aws.amazon.com/neptune/latest/userguide/engine-releases.html)
- [appsync: workshop example](https://github.com/aws-samples/aws-appsync-calorie-tracker-workshop/)
- [audit logs](https://docs.aws.amazon.com/neptune/latest/userguide/auditing.html)
- [backup & restore](https://docs.aws.amazon.com/neptune/latest/userguide/backup-restore-overview.html)
- [data: bulk load tutorial](https://docs.aws.amazon.com/neptune/latest/userguide/bulk-load-tutorial-IAM.html)
- [data: bulk load user guide](https://docs.aws.amazon.com/neptune/latest/userguide/bulk-load.html)
- [data: export](https://docs.aws.amazon.com/neptune/latest/userguide/machine-learning-data-export.html)
- [db: clones](https://docs.aws.amazon.com/neptune/latest/userguide/manage-console-cloning.html)
- [db: clusters](https://docs.aws.amazon.com/neptune/latest/userguide/feature-overview-db-clusters.html)
- [db: fast reset](https://docs.aws.amazon.com/neptune/latest/userguide/manage-console-fast-reset.html)
- [db: parameter groups](https://docs.aws.amazon.com/neptune/latest/userguide/parameters.html)
- [dfe engine](https://docs.aws.amazon.com/neptune/latest/userguide/neptune-dfe-engine.html)
- [elb: examples with neptune gremlin client](https://aws.amazon.com/blogs/database/load-balance-graph-queries-using-the-amazon-neptune-gremlin-client/)
- [endoints: intro](https://docs.aws.amazon.com/neptune/latest/userguide/feature-overview-endpoints.html)
- [endpoints: custom](https://docs.aws.amazon.com/neptune/latest/userguide/feature-custom-endpoint-membership.html)
- [error codes](https://docs.aws.amazon.com/neptune/latest/userguide/errors-engine-codes.html)
- [events](https://docs.aws.amazon.com/neptune/latest/userguide/events.html)
- [getting started: 7 videos 9 hrs](https://pages.awscloud.com/AWS-Learning-Path-Getting-Started-with-Amazon-Neptune_2020_LP_0009-DAT.html)
- [getting started](https://docs.aws.amazon.com/neptune/latest/userguide/get-started.html)
- [graph notebooks](https://docs.aws.amazon.com/neptune/latest/userguide/graph-notebooks.html)
- [instance status checks](https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-status.html)
- [instance types](https://docs.aws.amazon.com/neptune/latest/userguide/instance-types.html)
- [kinesis: data stream example](https://github.com/aws-samples/amazon-neptune-samples/tree/master/gremlin/stream-2-neptune)
- [lambda: examples](https://docs.aws.amazon.com/neptune/latest/userguide/lambda-functions.html)
- [landing page](https://aws.amazon.com/neptune/?did=ap_card&trk=ap_card)
- [lookup cache](https://docs.aws.amazon.com/neptune/latest/userguide/feature-overview-lookup-cache.html)
- [read replicas](https://docs.aws.amazon.com/neptune/latest/userguide/manage-console-create-replica.html)
- [running local](https://docs.aws.amazon.com/neptune/latest/userguide/graph-notebooks.html)
- [security](https://docs.aws.amazon.com/neptune/latest/userguide/security.html)
- [skillbuilder course](https://explore.skillbuilder.aws/learn/course/internal/view/elearning/14165/getting-started-with-amazon-neptune)
- [slideshare: graph data model and queries with neptune](https://www.slideshare.net/AmazonWebServices/work-backwards-to-your-graph-data-model-queries-with-amazon-neptune-dat330-aws-reinvent-2018)
- [slideshare: migrating to neptune](https://www.slideshare.net/AmazonWebServices/migrating-to-amazon-neptune-dat338-aws-reinvent-2018?qid=54cd934d-a746-48de-97a4-84321f6250f8)
- [slideshare: onramp to graph dbs & neptune](https://www.slideshare.net/AmazonWebServices/onramp-to-graph-databases-and-amazon-neptune-dat335-aws-reinvent-2018?qid=e677d773-0cb1-452d-95a3-b0be4d1dc7d9)
- [storage](https://docs.aws.amazon.com/neptune/latest/userguide/feature-overview-storage.html)
- [tagging resources](https://docs.aws.amazon.com/neptune/latest/userguide/tagging.html)
- [tools and utilities](https://github.com/awslabs/amazon-neptune-tools)
- [transactions: intro](https://docs.aws.amazon.com/neptune/latest/userguide/transactions.html)
- [transactions: isolation levels](https://docs.aws.amazon.com/neptune/latest/userguide/transactions-neptune.html)
- [user guide](https://docs.aws.amazon.com/neptune/latest/userguide/intro.html)

### opensource

- [convert graphML to neptune](https://github.com/awslabs/amazon-neptune-tools/blob/master/graphml2csv/README.md)
- [open cycpher](https://opencypher.org/)
- [apache tinkerpop](https://tinkerpop.apache.org/)
- [w3c RDF](https://www.w3.org/RDF/)
- [w3c SPARQL](https://www.w3.org/TR/sparql11-query/)
- [neptune jdbc driver](https://github.com/aws/amazon-neptune-jdbc-driver)
- [workbench: graph notebook project](https://github.com/aws/graph-notebook)

## best practices

- you should probably re-read the following links
  - graph data model, dictionary
  - transactions, specifically the conflict resolution section
  - working with custom endpoints
  - dfe engine
- optimal concurrency for writing or querying data is twice the number of vCPUs:
- storage
  - avoid using property keys and user-facing values that are temporary in nature.
  - data model changes should be loaded onto a new DB cluster.
    - or atleast using the fast reset api
  - split large transactions into smaller ones and allow time between them so that the associated internal logs have a chance to expire and release their internal storage for re-use by subsequent logs.
    - large amounts of data generate correspondingly large internal logs, which can permanently increase the high water mark of the internal log space
  - shrink allocated storage space when you have a large amount of unused allocated space is migrate to a new DB cluster.
    - e.g. via the data export + import tools
    - FYI: Creating and restoring a snapshot does not reduce the amount of storage allocated for your DB cluster, because a snapshot retains the original image of the cluster's underlying storage
- read replicas
  - should always be equal to/larger than the writer instance
    - avoids the larger writer instance from handling changes too quickly for the reader to maintain pace.
  - Disable any DNS caching settings to force DNS resolution each time.
    - neptune uses DNS to naively round-robin requests
  - If you want to load balance queries to distribute the read workload for a DB cluster,
    - you must manage that in your application
    - & use instance endpoints to connect directly to Neptune replicas to balance the load.
      - the DNS round robin doesnt consider load, its a naive routing mechanism
        - If a client opens a lot of connections before the DNS entry changes, all the connection requests are sent to a single Neptune instance

### anti patterns

- avoid creating ID properties

## features

- up to 15 read replicas for highly availability
- create point-in-time copies, configure continuous backup to S3 with replication across Availability Zones
- supports Three popular graph query languages: Apache TinkerPop, Neo4j OpenCypher and RDF/SPARQL
- quorum system for read/write

### pricing

- pay for the compute, I/O, and storage costs that your workload requires.
  - ballpark: costs break down to about 85 percent EC2 instances, 10 percent storage, and 5 percent I/O, but costs vary based on the workload.
- instance hosting: on demand by hour
  - primary instances used for read-write workloads
  - read replicas used to scale reads and enhance failover
  - Neptune workbench instances: work with your Neptune cluster using Jupyter notebooks (hosted by Amazon SageMaker).
- storage consumed: space actually allocated per gigabyte per month
  - determined by the storage high water mark, which is the maximum amount allocated to the cluster volume at any time during its existence.
- database backups and customer-initiated database cluster snapshots
  - bill separately from storage, as backup storage
- i/o: billed in per million request increments
  - requests in
  - data out
- workbench
  - T3 and T4g instance types for less than $0.10 per hour.
  - billed for workbench resources through Amazon SageMaker, separately from your Neptune billing.
- FYI
  - even if user data is removed from a cluster volume, such as by a drop query like g.V().drop(), the total allocated space remains the same. Neptune does automatically optimize the unused allocated space for reuse in the future.
  - Although your data is replicated into six copies, you are only billed for one copy of the data.
  - clones point to the same cluster volume that your DB cluster itself uses, so there is no additional storage charge for the original data

## terms

## basics

- availability: You can delete the cluster volume and its data only after deleting all of its DB instances.
  - six copies of your Neptune data are maintained across three AZs
  - failing db nodes auto detected and replaced
  - failing db processes auto detected and recycled
  - replicas auto promoted to primary during failover
  - customer-specific failover order
- performance
  - scale out read traffic across read replicas
  - reader endpoint balances connections across read replicas

### Data model

#### Four position QUAD element

- the basic unit of Amazon Neptune graph data; A set of quad statements with shared resource identifiers creates a graph.
  - S: subject
  - P: predicate
  - O: object
  - G: graph
- Each quad is a statement that makes an assertion about one or more resources.
  - can assert the existence of a relationship between two resources
  - can attach a property (key-value pair) to a resource
- statement example
  - A relationship between two vertices can be represented by storing the source vertex identifier in the S position, the target vertex identifier in the O position, and the edge label in the P position.
  - A property can be represented by storing the element identifier in the S position, the property key in the P position, and the property value in the O position

#### dictionary

- most user-facing values are stored separately in a dictionary
- The dictionary contains a forward mapping of user-facing values to 8-byte IDs in a value_to_id index.

#### indexes

- neptune actually uses an index storing 8 byte identifiers that reference the actual dictionary values
  - All user-facing values that would go in S, P, or G indexes are stored in the dictionary in this way.
  - In the O index, numeric values are stored directly in the index (inlined). This includes date and datetime values (represented as milliseconds from the epoch).
  - All other user-facing values that would go in the O index are stored in the dictionary and represented in the index by IDs.
- neptune only enables 3 out of the 6 available indexes by default
  - you can enable the OSGP Index Creation Using Lab Mode

#### Graph implementations

- each model has its own query language
- property vs RDF
  - property: your workload requires applying computations over edge attributes in the course of a graph traversal, or model bi-directional relationships
    - no schema and no predefined vocabularies for property names and labels; you must create and enforce constraints around naming of labels and such
    - support edge properties, making it easy to associate edge attributes with the edge definition
    - allows you to create multiple disconnected subgraphs within the same dataset, but has no equivalent to named graphs that allows you to identify and address individual subgraphs.
  - RDF: you need to differentiate between and manage multiple subgraphs in your dataset
    - has predefined schema vocabularies with well-understood data modelling semantics for specifying class and property schema elements
    - predefined domain-specific vocabularies such as vCard, FOAF, Dublin Core and SKOS for describing resources in different domains
    - designed to make it easy to share and publish data with fixed, well-understood semantics.
      - To qualify an edge in RDF with additional data, you must use intermediate nodes or blank nodes
    - supports the concept of named graphs, allowing you to group a set of RDF statements and identify them with a URI

##### Property Graph

- Apache tinkerpop's gremlin traversal language
  - check the neptune property graph file
- neo4j's opencypher
  - it has a file too

##### Resource Description Framework (RDF)

- w3c's SPARQL query language

### Performance

- directly related to how much of the graph a query must touch
  - choose domain-meaningful edge labels
  - discover only what is absolutely necessary
  - create verticies > properties
    - sometimes even store the same data twice, e.g. as a vertex AND as a property
  - create properties > verticies
    - if the creation of a vertex would disporportionately increase the total edges connected to it
  - consider storing other data outside of the graph, e.g. in another database
  - avoid supernodes: verticies that are disporportionately connected to other vertices
    - the issue being: any graph traversal that goes via such a vertex will have to look at most if not all of the edges connected to that vertex as part of a traversal.

#### Lookup Cache

- only available on an R5d instance type, where it is automatically enabled by default
- improves read performance for queries with frequent, repetitive lookups of property values or RDF literals
- temporarily stores these values in the NVMe SSD volume where they can be accessed rapidly.
- use cases
  - Read queries that return the properties of a large number of vertices and edges, or many RDF triples
  - long-running read queries that return a large number of:
    - full names from an identity graph
    - IP addresses from a fraud-detection graph
- FYI: only pay for this shiz if the following are ALL true
  - observing increased latency in read queries.
  - observing a drop in the BufferCacheHitRatio CloudWatch metric when running read queries
  - read queries are spending a lot of time in materializing return values prior to rendering the results

#### Materialization costs

- assess the materialization costs of a query with the Gremlin profile API.
- Under "Index Operations', it shows the number of terms materialized during execution
- check the lookup cache docs for an example

#### DFE engine

- optionally enable for high perf; set via db parameter groups
- uses DB instance resources such as CPU cores, memory, and I/O more efficiently than the original Neptune engine.
- uses pre-generated statistics about your Neptune graph data to make informed decisions about how to structure queries
- supports a wide variety of plan types, including left-deep, bushy, and hybrid ones.
  - but only a subset of SPARQL and Gremlin query constructs.
    - Gremlin: generally the subset of queries that contain a chain of traversals which do not contain some of the more complex steps.
- read the docs

### Transactions

- Neptune is designed to support highly concurrent online transactional processing (OLTP) workloads over data graphs
  - neither SPARQL nor GREMLIN define standard transaction mechanisms for concurrent query processing
  - neptune, however, enforces strict semantics to help avoid data anomalies.
- read only isolation: snapshot isolation semantics via MVCC
  - a read-only query logically operates on a consistent snapshot of the database taken when query evaluation begins.
  - there can be a small replication lag between the writer and read replicas.
    - for the strongest guarantee: send the query to the writer endpoint itself rather than to a read replica.
- read after mutation isolation: READ COMMITTED transaction isolation
  - also guards against fuzzy and phantom reads
  - achieved by locking records and ranges of records when reading data

#### Gremlin

- READ queries: `!isMutationQuery()`
- MUTATION queries:
  - contains any query-path steps such as addE(), addV(), property(), or drop()
  - all script based session queries, whether read or mutation, are classified as mutation queries
- Neptune uses quorum writes that make six copies of your data across three Availability Zones,
  - four out of those six storage nodes must acknowledge a write for it to be considered durable

#### sparql

- READ queries: SELECT, ASK, CONSTRUCT, and DESCRIBE
- MUTATION queries: INSERT and DELETE

#### opencycpher

- abcd

### db cluster

- manages access to your data through queries. A cluster consists of:
  - primary database
  - read replicas: Up to 15
- compute layer
  - single-writer architecture: no more than a single (primary db) writer instance can be provisioned.
  - read replicas: up to 15;
- storage layer: spans multiple AZs
  - cluster volume: designed for reliability and high availability; copies data across AZs in a single region.

#### primary database

- accepts read and write operations
- coordinates all write operations to the DB cluster's underlying storage volume
- There can only be one primary DB instance in a Neptune DB cluster.
  - Neptune automatically fails over to one of the read-replica instances with a priority that you can specify.

#### read replicas

- connects to the same storage volume as the primary database instance
- Reads are eventually consistent: generally in the single-digit milliseconds, but potentially up to 100 ms under extremely heavy traffic.
- Each read-replica DB instance has its own endpoint.

#### endpoints

- Each Neptune connection is handled by a specific DB instance.
  - the host name and port that you specify point to an intermediate handler called an endpoint
  - the intermediate endpoint abstracts away the underlying connections so that you don't have to hardcode the hostnames, or write your own logic for rerouting connections when some DB instances are unavailable.

##### cluster endpoint

- e.g. `mydbcluster.cluster-123456789012.us-east-1.neptune.amazonaws.com:8182`
- connects to the current primary database instance for the database cluster.
- Each Neptune DB cluster has a cluster endpoint and one primary DB instance.
- provides failover support for read/write connections to the DB cluster
- use cases: any R/W operation
  - all write operations on the DB cluster, including inserts, updates, deletes, and data definition language (DDL) changes
  - read operations, such as queries.

##### reader endpoint

- connects to one of the available Neptune replicas
- if there is more than one replica
  - uses DNS routing to load balance (round-robin) requests across all of the read replicas in the cluster.
    - changes the host that the DNS entry points to
    - Each time you resolve the DNS, you get a different IP, and connections are opened against those IPs
    - if using web sockets
      - Ensure that your client resolves the DNS entry each time it connects.
      - Close the connection and reconnect.
- use cases: Read operations

##### instance endpoints

- e.g. `mydbinstance.123456789012.us-east-1.neptune.amazonaws.com:8182`
- connects to a specific database instance in the cluster;
- use cases
  - scenerios where using the cluster endpoint or reader endpoint might not be appropriate
    - e.g. fine-grained load balancing based on workload type
  - direct control over connections to the DB cluster,

##### custom endpoints

- e.g. `myendpoint.cluster-custom-123456789012.us-east-1.neptune.amazonaws.com:8182`
- represents a set of DB instances that you choose
- Neptune chooses one of the instances in the group to handle the connection
- create up to five custom endpoints for each provisioned Neptune cluster.
- FYI
  - load-balances db connections based on criteria other than the read-only or read/write capability of the DB instances
  - make sure that all the instances within that group share the same performance and memory capacity characteristics
- use cases
  - intended for advanced users with specialized kinds of workloads where it isn't practical to keep all the Neptune Replicas in the cluster identical
  - can adjust the capacity of the DB instances used with each connection.
  - custom endpoints that connect to groups of instances with different instance classes, you can then direct users with different performance needs to the endpoints that best suit their use cases.
- creating: abcd
- viewing: abcd
- editing: abcd
- deleting: abcd

#### Parameter Groups

- db parameter groups: apply at the instance level
- db cluster parameter groups: apply to every instance in the cluster
- default parameter & cluster parameter groups
  - every account has them, cant be modified
- customer parameter and cluster parameter groups
  - all Neptune DB parameters are static
  - you must manually reboot each db instance before changes take effect

##### lab mode

- enable new features that are in the current Neptune engine release, but that aren't yet ready for production use and aren't enabled by default.
- read the docs on this when it becomes important
  - you need to restart both the primary, and each replica, plus some other gotchas

#### Instances

- DB instances are created by default with a firewall and a default security group that prevents access
  - To enable access, you must have a VPC security group with additional rules.
- choosing the right class:
  - number of concurrent requests
  - write latency
  - query complexity
  - query performance requirements
  - etc

##### right sizing

- based on your CPU and memory requirements
- the number of vCPUs on an instance determines the number of query threads that handle incoming queries
  - Each Neptune DB instance has a number of query threads equal to 2 x number of vCPUs on that instance
    - e.g. db.r5.large, has TWO vCPUs -> 4 processes writing data in parallel
    - e.g. r5.4xlarge, has 16 vCPUs, has 32 query threads, and can therefore process 32 queries concurrently.
  - subsequent queries that arrive while all query threads are occupied are put into a server-side queue,
    - processed in a FIFO manner as query threads become available.
    - server-side queue can hold approximately 8000 pending requests
- The amount of memory on an instance determines the size of the buffer cache

#### Storage

- uses a distributed and shared storage architecture that scales automatically as your database storage needs grow.
- cluster volume: which is a single, virtual volume that uses Non-Volatile Memory Express (NVMe) SSD-based drives
  - consists of a collection of logical blocks known as segments
  - Each segment is allocated 10 gigabytes (GB) of storage.
  - The data in each segment is replicated into six copies, allocated across three AZs in the DB cluster's region.
- contains all your user data, indices and dictionaries, internal metadata such as internal transaction logs
  - cannot exceed the maximum size of the cluster volume:
    - 128 tebibytes (TiB) in all regions except China and GovCloud, where it is 64 TiB
- When a Neptune DB cluster is created, it is allocated a single segment of 10 GB.
  - before capacity breaches allocated storage, Neptune automatically expands the cluster volume by adding new segments

### Workbench

- run jupyter notebooks hosted in SageMaker
- automatically loads the latest release of aws graph notebook project from github
- its not free, check the pricing section

#### graph notebook project

- easy way to interact with graph databases using Jupyter notebooks.
- connect to any graph (local/cloud) database that supports the Apache TinkerPop, openCypher or the RDF SPARQL graph models.

#### jupyter/lab notebooks

- all use an Amazon Linux 2 and JupyterLab 3 environment
- create a notebook using the Neptune workbench in the AWS Management Console
  - when creating a new Neptune DB cluster.
  - or from the notebook menu

### Audit Logs

- View, download, or watch database log files using the Neptune console.

### Events

- Subscribe to Neptune events within the neptune console

### Errors

- ConcurrentModificationException: When transactions are canceled because of unresolvable conflicts or lock-wait timeouts
  - occur when multiple concurrent requests attempt to modify the same elements in the graph
  - when instances of this error is low
    - an exponential backoff-based retry mechanism works well as a way to handle them
  - when instances of this error is high
    - modify your app logic to serialize updates that are likely to conflict with each other.
- ReadOnlyViolationException: occur if the client attempts to write to a database instance that is no longer the primary.
- ThrottlingException: server-side queue is full and no more queries can be accepted

### http API

#### status endpoint

- used for a bunch of stuff
- specify your own queryId value in the HTTP header,
  - enables you to cancel/inspect executed queries

```sh
# check a query
curl https://your-neptune-endpoint:port/gremlin/status \
    -d "queryId=4d5c4fae-aa30-41cf-9e1f-91e6b7dd6f47"
```

#### summary endpoint

- returns a read-only list of graph data size and content:node and edge labels and property keys, along with counts of nodes, edges, and properties.
- summary data is drawn from the DFE statistics computed by the Neptune DFE engine during runtime
  - if you havent disabled statistics, its periodically updated
  - else manually trigger a statistics update right before retrieving the summary.

```sh

# drop the mode param for basic
curl https://your-neptune-host:port/pg/statistics/summary?mode=detailed
```

### security

- network isolation via VPC
  - endpoints only accessible within VPC/peered connections
- security groups: firewall for the associated Neptune DB instance;

#### encryption

- see the KMS file

## considerations

- db engine version
- instances
  - instance class
  - burstable
  - notebook configuration: enables access to the cluster
- high availability: can be disabled
- Multi-AZ deployment
  - specifying Multi-AZ when creating a DB cluster.
  - If a DB cluster is in a single Availability Zone, you can make it a Multi-AZ DB cluster adding a Neptune replica in a different Availability Zone.
- db instance identifier: must be unique per account per region
- vpc, subnets, security group
- db cluster identifier, db port (e.g. 8192), parameter group
- iam authnz, encryption at rest: both can be disabled/enabled at creation
- failover
- backup retention period & window
- version maintenance and window
- sagemaker
  - direct access

## integrations

- Neptune only allows connections from clients located in the same VPC as the Neptune cluster.
- you have to one of:
  - direct access to the DB: an A/NLB otherwise
  - api access: api gateway + lambda
    - optionally run lambda outside a VPC and connect to neptune via an ELB

### IAM

- user authn at creation
- roles can be assigned at anytime (e.g. to load data from s3)

### kinesis

#### Data Streams

- in high write throughput scenarios improve the reliability, performance and scalability by
  - sending logical writes to an kinsesis Data Stream
  - Lambda function polls the stream and issues batches of writes to the underlying Neptune database.
- A Kinesis Data Stream is provisioned to accept write requests from client applications, which act as record producers.
- Clients can use the Amazon Kinesis Data Streams API or Kinesis Agent to write individual records to the data stream.
- An AWS Lambda function processes records in the data stream.
  - Create a Lambda function and an event source mapping.
  - The event source mapping tells Lambda to send records from your data stream to the Lambda function, which uses a Gremlin or SPARQL client to submit write requests to the Neptune cluster endpoint.
  - The Lambda function issues batch writes to Neptune. Each batch is executed in the context of a single transaction.
  - To increase the speed at which the function processes records, add shards to the data stream.
- best practices
  - implement record aggregation in the client, and deaggregation in your Lambda functions
    - check the kinesis file for the record aggregation link
  - Consider pulling large batches from the stream by configuring the batch size property in the event source mapping, but writing smaller batches to Neptune one after another in a single Lambda invocation.
    - e.g. pulling 1000 records from the stream, and issuing 10 batch writes, each of 100 records, to Neptune during a single Lambda invocation.
    - allows you to tune batch write size according to factors such as the instance size of the Neptune database leader node and the complexity of your writes, while reusing a connection for the several batch writes you issue to Neptune during a single Lambda invocation
    - be careful as errors causes the entire batch to fail
  - control concurrency by adjusting the number of shards in your Kinesis Data Stream.
    - e.g. two shards will result in two concurrent Lambda invocations, one per shard.
    - set the number of shards to no more than 2x the number of vCPUs on the Neptune leader node.
  - Increasing the number of shards in order to increase concurrency and throughput will therefore increase costs.
    - alternatively at the expense of additional engineering effort, you can increase concurrency using the threading model particular to your Lambda runtime.
  - ensure that logical writes are wholly independent of one another such that they can be executed out of insert order, or direct dependent writes to the same shard using partition keys to group data by shard.

### VPC

- requires atleast two subnets in two different Availability Zones for high availability
  - dude stop spamming this everywhere, this is a default for high availability

### SageMaker

- for analyzing neptune graphs via jupyter notebooks
- i think the notebook instances for neptune are managed via the sagemaker console

### Glue

- getting data into neptune

### OpenSearch

- Amazon OpenSearch Service for full-text search capabilities

### DMS

- migrating data to a neptune cluster

### EC2

- autoscaling groups for read replicas
  - hmm this might be AWS autoscaling groups and not EC2 autoscaling groups

### ELB

- for both A/NLB
  - your Neptune cluster is run in at least two subnets in two Availability Zones, with each subnet in a different Availability Zone.
    - enables external clients to access the Neptune cluster endpoint, which always points to the primary instance in the cluster.
    - To enable access to the reader endpoint, which load balances connections across all the read replicas in the cluster, you will need to either create a second
      - target group and a listener configured with a different port
      - load balancer with a different DNS name.
  - The Neptune DB subnet group spans at least two subnets in two Availability Zones.
- ALB vs NLB
  - number of hops
    - NLB: one hop.
    - ALB: two hops between the client and the Neptune instance
  - service types
    - NLB: fully managed
    - ALB: third party proxy
- best practices
  - Restrict access to your cluster to a range of IP addresses using the security groups attached to the Neptune instances.
  - further restricting access by enabling IAM database authentication, requiring all HTTP requests be signed using AWS Signature Version 4, which requires changes to the client.
    - the client must sign the request using Neptune's DNS and include an HTTP Host header whose value is <neptune-cluster-dns:port>
      - i.e. the client must know the Neptune cluster's DNS and port in addition to the load balancer's DNS and port.

#### ALB

- Web connections from external clients terminate on an Application Load Balancer in a public subnet.
- The load balancer forwards requests to HAProxy running on an EC2 instance. This EC2 instance is registered in a target group belonging to the ALB.
- HAProxy is configured with the Neptune cluster endpoint DNS and port. Requests from the ALB are forwarded to the primary instance in the database cluster.
- FYI:
  - aws expicitly states HAProxy, but i'm sure Envoy would work just as well
- best practices
  - increase the availability of the publicly available endpoint by enabling multiple Availability Zones for the ALB, adding multiple HAProxy instances in each AZ, and load balancing across the HAProxy instances by including all instances in each ALB’s target group.
  - To enable access to the reader endpoint configure path-based routing either in the ALB, which will allow you to route to different HAProxy instances, or in HAProxy itself.
    - With path-based routing, the client would add a path suffix – such as /reader or /writer – to the request URI.
      - e.g. use http://<alb-dns>:80/gremlin/reader.
      - You will need to rewrite the path to remove this suffix in the ALB or HAProxy before passing the request to the appropriate Neptune endpoint.

#### NLB

- Web connections from external clients terminate on a Network Load Balancer in a public subnet.
- The load balancer forwards requests to the Neptune cluster endpoint (which then routes to the primary instance in the database cluster).
- The target IP addresses of the cluster endpoint are refreshed on a periodic basis by a Lambda function.
- This Lambda function is triggered by a CloudWatch event. When it fires, the function queries a DNS server for the IP addresses of the Neptune cluster endpoint. It registers new IP addresses with the load balancer’s target group, and deregisters any stale IP addresses
- best practices
  - you must use SSL termination and have your own SSL certificate on the proxy server. NLB, although a Layer 4 load balancer, supports TLS termination.
  - new cluster IPs are registered with the NLB as soon as they are identified. and stale IPs are removed (e.g. via health checks)
    - maintain a candidate list of IP addresses to be deregistered using a file stored in an S3 bucket.
      - theres a blog post link in ELB file

### API Gateway

- API Gateway exposes API operations that accept client requests and execute your backend Lambda functions.
- check the lambda section

### lambda

- execute gremlin/sparql queries, which can be exposed as endpoints via api gateway
- Neptune's VPC security group is configured to allow access from the AWS Lambda security group on the Neptune cluster's port.
- AWS Lambda is configured to access resources in your VPC.
  - allows Lambda to create elastic network interfaces (ENIs) that enable your function to connect securely to Neptune.
- The Lambda VPC configuration information includes at least 2 private subnets, allowing Lambda to run in high availability mode.
- The VPC security group that Lambda uses is permitted to access Neptune via an inbound rule on the Neptune VPC security group.
- Code running in your Lambda function uses a Gremlin or SPARQL client to submit queries to the Neptune cluster's cluster, reader and/or instance endpoints.
- best practices
  - to enable external internet access for your function, configure your Lambda security group to allow outbound connections and route outbound internet traffic via a NAT gateway attached to your VPC.
  - Lambda functions that are configured to run inside a VPC incurs an additional ENI start-up penalty
    - address resolution may be delayed when trying to connect to network resources.
  - Use a single connection and graph traversal source for the entire lifetime of the Lambda execution context.
    - If the Gremlin driver you’re using has a connection pool, configure it to use a single connection.
      - Hold the connection in a member variable so that it can be resued across invocations.
      - Concurrent client requests to the function will be handled by different function instances running in separate execution contexts – each with its own member variable connection.
  - Handle connection issues and retry connections in your function code.
    - unexpected network events can cause this connection to be terminated abruptly.
    - code your function to handle these connection issues and attempt a reconnection if necessary.
  - If your Lambda function modifies data in Neptune,
    - adopt a backoff-and-retry strategy to handle ConcurrentModificationException and ReadOnlyViolationException errors.

### AppSync

### kms

### s3

### cloudtrail

### SNS

### Backup

### cloudwatch
